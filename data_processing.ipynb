{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from subprocess import call\n",
    "import shutil\n",
    "\n",
    "BASE_DIR = \"training_data\"\n",
    "OUTPUT_DIR = \"number_plate\"\n",
    "with open(os.path.join(BASE_DIR, \"classes.txt\")) as f:\n",
    "    classes = f.readlines()\n",
    "    classes = [x.strip() for x in classes]\n",
    "\n",
    "# desired_classes = list(set(classes) - set([\"number_plate\"]))\n",
    "desired_classes = [\"number_plate\"]\n",
    "desired_classes_indices = [classes.index(cls.lower()) for cls in desired_classes]\n",
    "\n",
    "annotations = glob.glob(os.path.join(BASE_DIR, \"labels\", \"*\"))\n",
    "annotations\n",
    "\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "\n",
    "if not os.path.exists(os.path.join(OUTPUT_DIR, \"labels\")):\n",
    "    os.mkdir(os.path.join(OUTPUT_DIR, \"labels\"))\n",
    "\n",
    "if not os.path.exists(os.path.join(OUTPUT_DIR, \"images\")):\n",
    "    os.mkdir(os.path.join(OUTPUT_DIR, \"images\"))\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "for annotation_file in annotations:\n",
    "    desired_data = []\n",
    "    with open(annotation_file) as f:\n",
    "        data = [x.strip() for x in f.readlines()]\n",
    "        data_split = [x.split() for x in data]\n",
    "        for split in data_split:\n",
    "            if (\n",
    "                int(split[0]) in desired_classes_indices\n",
    "            ):  # If the current row is a desired class\n",
    "                desired_data.append(split)\n",
    "\n",
    "        for idx, desired in enumerate(desired_data):\n",
    "            # Replace the class index with the new index\n",
    "            desired[0] = str(desired_classes.index(classes[int(desired[0])].lower()))\n",
    "            desired_data[idx] = \" \".join(desired)\n",
    "\n",
    "    if len(desired_data) > 0:\n",
    "        with open(\n",
    "            os.path.join(OUTPUT_DIR, \"labels\", os.path.basename(annotation_file)), \"w\"\n",
    "        ) as f:\n",
    "            f.write(\"\\n\".join(desired_data))\n",
    "            print(\n",
    "                \"Wrote {} lines to {}\".format(\n",
    "                    len(desired_data),\n",
    "                    os.path.join(OUTPUT_DIR, os.path.basename(annotation_file)),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        image_file = os.path.join(\n",
    "            BASE_DIR, \"images\", os.path.basename(annotation_file).replace(\"txt\", \"png\")\n",
    "        )\n",
    "        output_image_path = os.path.join(OUTPUT_DIR, \"images\") + os.sep\n",
    "        print(f\"Copying {image_file} to {output_image_path}\")\n",
    "\n",
    "        if not os.path.exists(image_file):\n",
    "            raise ValueError()\n",
    "\n",
    "        shutil.copy(image_file, output_image_path)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, \"classes.txt\"), \"w\") as f:\n",
    "    f.write(\"\\n\".join(desired_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "YOLO_DATA_DIR = \"car_labels\"\n",
    "OUTPUT_DIR = \"car_classification\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(YOLO_DATA_DIR, \"classes.txt\")) as f:\n",
    "    classes = f.readlines()\n",
    "    classes = [x.strip() for x in classes]\n",
    "\n",
    "for class_name in classes:\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, class_name), exist_ok=True)\n",
    "\n",
    "# Iterate through YOLO annotation files\n",
    "for annotation_file in os.listdir(os.path.join(YOLO_DATA_DIR, \"labels\")):\n",
    "    with open(os.path.join(YOLO_DATA_DIR, \"labels\", annotation_file), \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [x.strip() for x in lines]\n",
    "\n",
    "    # Process each bounding box in the annotation file\n",
    "    for line in lines:\n",
    "        # Extract class label and bounding box coordinates\n",
    "        class_label, x_center, y_center, width, height = map(float, line.split())\n",
    "\n",
    "        # Calculate bounding box coordinates in pixel values\n",
    "        img_width, img_height = Image.open(os.path.join(YOLO_DATA_DIR, \"images\", annotation_file.replace(\"txt\", \"png\"))).size\n",
    "        x_min = int((x_center - width / 2) * img_width)\n",
    "        y_min = int((y_center - height / 2) * img_height)\n",
    "        x_max = int((x_center + width / 2) * img_width)\n",
    "        y_max = int((y_center + height / 2) * img_height)\n",
    "\n",
    "        # Crop the region from the original image\n",
    "        image_path = os.path.join(YOLO_DATA_DIR, \"images\", annotation_file.replace(\"txt\", \"png\"))\n",
    "        image = Image.open(image_path)\n",
    "        cropped_image = image.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "        # Save the cropped image to the output directory with the class label as the filename\n",
    "        cropped_image.save(os.path.join(OUTPUT_DIR, classes[int(class_label)], annotation_file.replace(\"txt\", \"png\")))\n",
    "\n",
    "print(\"Conversion completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Productivity\\Github-Repos\\FYP-mass-surveillance-using-machine-learning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:414\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(path_img)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# split \u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m data_train, data_test, labels_train, labels_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, df\u001b[38;5;241m.\u001b[39mindex, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Function split \u001b[39;00m\n\u001b[0;32m     47\u001b[0m split_img_label(data_train,data_test,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mf:\\Productivity\\Github-Repos\\FYP-mass-surveillance-using-machine-learning\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mf:\\Productivity\\Github-Repos\\FYP-mass-surveillance-using-machine-learning\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:416\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import pandas as pd \n",
    "import os \n",
    "\n",
    "def split_img_label(data_train,data_test,folder_train,folder_test):\n",
    "    \n",
    "    os.mkdir(folder_train)\n",
    "    os.mkdir(folder_test)\n",
    "    \n",
    "    \n",
    "    train_ind=list(data_train.index)\n",
    "    test_ind=list(data_test.index)\n",
    "    \n",
    "    \n",
    "    # Train folder\n",
    "    for i in tqdm(range(len(train_ind))):\n",
    "        \n",
    "        os.system('cp '+data_train[train_ind[i]]+' ./'+ folder_train + '/'  +data_train[train_ind[i]].split('/')[2])\n",
    "        os.system('cp '+data_train[train_ind[i]].split('.png')[0]+'.txt'+'  ./'+ folder_train + '/'  +data_train[train_ind[i]].split('/')[2].split('.png')[0]+'.txt')\n",
    "    \n",
    "    # Test folder\n",
    "    for j in tqdm(range(len(test_ind))):\n",
    "        \n",
    "        os.system('cp '+data_test[test_ind[j]]+' ./'+ folder_test + '/'  +data_test[test_ind[j]].split('/')[2])\n",
    "        os.system('cp '+data_test[test_ind[j]].split('.png')[0]+'.txt'+'  ./'+ folder_test + '/'  +data_test[test_ind[j]].split('/')[2].split('.png')[0]+'.txt')\n",
    "\n",
    "PATH = './Color Classification/'\n",
    "list_img=[img for img in os.listdir(PATH) if img.endswith('.png')==True]\n",
    "list_txt=[img for img in os.listdir(PATH) if img.endswith('.txt')==True]\n",
    "\n",
    "path_img=[]\n",
    "\n",
    "for i in range (len(list_img)):\n",
    "    path_img.append(PATH+list_img[i])\n",
    "    \n",
    "df=pd.DataFrame(path_img)\n",
    "\n",
    "# split \n",
    "data_train, data_test, labels_train, labels_test = train_test_split(df[0], df.index, test_size=0.20, random_state=42)\n",
    "\n",
    "# Function split \n",
    "split_img_label(data_train,data_test,\"train\",\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Autosplitting images from Color Classification\n",
      "100%|██████████| 486/486 [00:00<00:00, 606.72it/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.data.utils import autosplit\n",
    "\n",
    "autosplit(\"Color Classification\", weights=(0.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
